{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn_Modelling.csv başarıyla Churn_Modelling.xlsx olarak kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV dosyasını okuma\n",
    "csv_file = 'Churn_Modelling.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Excel dosyasına yazma\n",
    "excel_file = 'Churn_Modelling.xlsx'\n",
    "df.to_excel(excel_file, index=False)\n",
    "\n",
    "print(f'{csv_file} başarıyla {excel_file} olarak kaydedildi.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1 Görevi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, Başarı: 0.7853333333333333\n",
      "k=3, Başarı: 0.8003333333333333\n",
      "k=5, Başarı: 0.8073333333333333\n",
      "k=7, Başarı: 0.81\n",
      "k=9, Başarı: 0.8116666666666666\n",
      "k=11, Başarı: 0.8106666666666666\n",
      "Toplam Başarı: 0.8106666666666666\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Veriyi Churn_Modelling.xlsx veriyi yükleme yapıcak\n",
    "df = pd.read_excel(\"Churn_Modelling.xlsx\")\n",
    "\n",
    "# O1: Sözel kategorik tipteki özellikleri sayısallaştırma.\n",
    "# Geography sütununu ve Gender Sütununu pd.Categorical sayesinde kategorik veri tipine çevirir.\n",
    "df['Geography'] = pd.Categorical(df['Geography']).codes\n",
    "df['Gender'] = pd.Categorical(df['Gender']).codes\n",
    "\n",
    "# O2: Boş değerleri en çok görülen değer ile doldur.\n",
    "# Bunu yaparken DataFrame'in içindeki boş olan yerleri doldurur bunu yaparken mod() işleminden yararlanır çünkü mod işlemi en sık görülen değerdir.\n",
    "# iloc[0] ifadesi'de aldığımız modu DataFrame'deki ilk satırı almamıza olanak sağlar ama mod değeri yani aynı tekrar'a sahip olan değerler varsa ilk en çok tekrarlanan değeri almamızı sağlar.\n",
    "df = df.fillna(df.mode().iloc[0])\n",
    "\n",
    "# O3: Alakasız kolonları sil.\n",
    "# Burada ise df.drop() yani drop fonksiyonu en üstteki satır'da olan [RowNumber,CustomerId,Surname] saütunlarını kaldırır.\n",
    "# Bu sütunların kaldırılma sebepi ise RowNumber ve CustomerId  yukarıdan aşağıya artan değer gösterir 1'er 1'er artar bu yüzden farklı değerler olduğu için sınıflandırmaya uygun olmaz o yüzden bu sütunları silmemiz gerekir.\n",
    "df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "# O4: Min-Max normalizasyonu\n",
    "# Min-Max normalizasyonu için Min yani minimum ve Max yani Maximum değerler belirlenir sayısal değerleri bir aralığa koymak için kullanılır.\n",
    "# Pd.DataFrame() ile veriyi normal veriyi pandas'a çevirmemizi sağlar.\n",
    "# Scaler orjinal veriyi dataframe(df) olmasını sağlar \n",
    "# Fit sayesinde veriyi normal haline çevirme işlemi yapar.\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# O5: Veriyi random olarak karıştır ve kNN algoritması ile sınıflandırma\n",
    "# np.random.seed(42) seed'rastgele sayı üretmemiz için olanak sağlar.\n",
    "np.random.seed(42)  \n",
    "# df_normalicez_ fonksiyonu bize DatFrame'in uzunluğunu gösterir.\n",
    "# df_normalized.iloc[ ] Rastele sıralanmış satırları satırları bulmamızı sağlar.\n",
    "# np.random.permutation Sayı aralığını rastgele karıştırmamızı sağlar.\n",
    "df_shuffled = df_normalized.iloc[np.random.permutation(len(df_normalized))]\n",
    "\n",
    "# kNN algoritması ile sınıflandırma ve başarı oranını hesaplama\n",
    "# k_values'da listenin içine bize görevde verilen değerlerin atamasını sağlar.\n",
    "k_values = [1, 3, 5, 7, 9, 11]\n",
    "# Farklı komşu sayıları için  k'nın sağladığı doğruluk değerlerini listenin içine atar.\n",
    "accuracies = []\n",
    "\n",
    "for k in k_values:\n",
    "    # np.random.seed(42) seed'rastgele sayı üretmemiz için olanak sağlar.\n",
    "    np.random.seed(42)  # Her bir k için farklı rastgele tohum kullan\n",
    "    \n",
    "    # Aşağıdaki kod satırında drop ile Bağımsız x değişkeninde Exited sütununu siler\n",
    "    X = df_shuffled.drop('Exited', axis=1)\n",
    "    # Aşağıdaki kod satırında ise y değişkeninde drop olmadığı için y değişkeni exited sütununu içermiş olur.\n",
    "    y = df_shuffled['Exited']\n",
    "    # %30'unu test_size yani test eğitim seti olarak ayırır geriye kalan %70 ise Eğitim veri seti olur.\n",
    "    # random state ise rasgele sayı üretimini 42 ile başlatır .\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    # n_neighbors k'nın komşu sayısını bulmasını sağlar .\n",
    "    # Aşağıdaki kod satırı metric değerini öklid'e eşitliyoruz yani (euclidean) değerine eşitlemiş oluyoruz öklid uzunluğunu hesaplıyor.\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=k,metric=\"euclidean\")\n",
    "    # Eğitim seti X_train ve Y_train üzerinde sağlanır X_daha önceden drop olayında söylediğim gibi bağımsız değişkendir Y_train ise Bağımlı değişkendir.\n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "    # predict sayesinde bağımsız değişkenlere bağlanarak tahminlerini yapar.\n",
    "    predictions = knn_classifier.predict(X_test)\n",
    "    # Modelin tahminleri ile gerçek değerleri karşılaştırarak doğruluk değeri hesaplanır. Doğruluk değeri, tüm örnekler içinde doğru tahmin edilen örneklerin oranını ifade eder.\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    # Değeri eklemeyi sağlar.\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Sonuçları k'nın eşitlik değerleri [1,3,5,7,9,11] için sonuçları yazdırır.\n",
    "for k, acc in zip(k_values, accuracies):\n",
    "    print(f'k={k}, Başarı: {acc}')\n",
    "\n",
    "# Toplam başarı oranını yazdırmaması sağlar.\n",
    "total_accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Toplam Başarı: {total_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1 Görevi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam Başarı: 0.6986666666666667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Veriyi Churn_Modelling.xlsx veriyi yükleme yapıcak\n",
    "df = pd.read_excel(\"Churn_Modelling.xlsx\")\n",
    "\n",
    "# O1: Sözel kategorik tipteki özellikleri sayısallaştırma.\n",
    "# Geography sütununu ve Gender Sütununu pd.Categorical sayesinde kategorik veri tipine çevirir.\n",
    "df['Geography'] = pd.Categorical(df['Geography']).codes\n",
    "df['Gender'] = pd.Categorical(df['Gender']).codes\n",
    "\n",
    "# O2: Boş değerleri en çok görülen değer ile doldur.\n",
    "# Bunu yaparken DataFrame'in içindeki boş olan yerleri doldurur bunu yaparken mod() işleminden yararlanır çünkü mod işlemi en sık görülen değerdir.\n",
    "# iloc[0] ifadesi'de aldığımız modu DataFrame'deki ilk satırı almamıza olanak sağlar ama mod değeri yani aynı tekrar'a sahip olan değerler varsa ilk en çok tekrarlanan değeri almamızı sağlar.\n",
    "df = df.fillna(df.mode().iloc[0])\n",
    "\n",
    "# O3: Alakasız kolonları sil.\n",
    "# Burada ise df.drop() yani drop fonksiyonu en üstteki satır'da olan [RowNumber,CustomerId,Surname] saütunlarını kaldırır.\n",
    "# Bu sütunların kaldırılma sebepi ise RowNumber ve CustomerId  yukarıdan aşağıya artan değer gösterir 1'er 1'er artar bu yüzden farklı değerler olduğu için sınıflandırmaya uygun olmaz o yüzden bu sütunları silmemiz gerekir.\n",
    "df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "# O4: Min-Max normalizasyonu\n",
    "# Min-Max normalizasyonu için Min yani minimum ve Max yani Maximum değerler belirlenir sayısal değerleri bir aralığa koymak için kullanılır.\n",
    "# Pd.DataFrame() ile veriyi normal veriyi pandas'a çevirmemizi sağlar.\n",
    "# Scaler orjinal veriyi dataframe(df) olmasını sağlar \n",
    "# Fit sayesinde veriyi normal haline çevirme işlemini yapıcaktır.\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# O5: Veriyi random olarak karıştır ve kNN algoritması ile sınıflandırma\n",
    "# np.random.seed(42) seed'rastgele sayı üretmemiz için olanak sağlar.\n",
    "np.random.seed(42)\n",
    "df_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Her bir test örneği için k adet en yakın komşuyu kullanarak sınıflandırma yapıcaktır.\n",
    "k = 3\n",
    "accuracies = []\n",
    "\n",
    "for _ in range(1):  # 100 farklı random durum için deneme yapabilirsiniz.\n",
    "    # %70'ini train_set yani eğitim seti olarak ayırır, geriye kalan %30 ise test_seti olur.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_shuffled.drop('Exited', axis=1), df_shuffled['Exited'], test_size=0.3, random_state=42)\n",
    "    \n",
    "    # kNN algoritması için her bir test örneği için k adet en yakın komşuyu bulma yani (k=3) bulmasını sağlıyor.\n",
    "    predicted_classes = []\n",
    "    for index, test_row in X_test.iterrows():\n",
    "        # Her bir sınıf için k adet en yakın komşuyu bulma\n",
    "        positive_neighbors = X_train[y_train == 1].apply(lambda row: np.linalg.norm(row - test_row), axis=1).nsmallest(k)\n",
    "        # Exited'sütununda 1 ve 0 değerleri var değeri 1 olanları pozitif olarak alıyor.\n",
    "        # Negatif olanları ise 0 olduğu zaman alıyor.\n",
    "\n",
    "        negative_neighbors = X_train[y_train == 0].apply(lambda row: np.linalg.norm(row - test_row), axis=1).nsmallest(k)\n",
    "        \n",
    "        # Pozitif ve negatif sınıfın k adet en yakın komşularının ortalamasını bulmasını sağlıyor.\n",
    "        positive_mean = positive_neighbors.index.to_numpy()\n",
    "        negative_mean = negative_neighbors.index.to_numpy()\n",
    "        \n",
    "        # Test örneğini pozitif ve negatif sınıfın ortalama vektörleri ile karşılaştırarak tahmin yapma\n",
    "        positive_distance = np.linalg.norm(test_row - X_train.loc[positive_mean].mean())\n",
    "        negative_distance = np.linalg.norm(test_row - X_train.loc[negative_mean].mean())\n",
    "        predicted_class = 1 if positive_distance < negative_distance else 0\n",
    "        predicted_classes.append(predicted_class)\n",
    "    \n",
    "    # Test seti için başarı oranını hesaplama işlemini yapar.\n",
    "    accuracy = accuracy_score(y_test, predicted_classes)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Sonuçları yazdırma işlemini gerçekleştirir.\n",
    "print(f'Toplam Başarı: {np.mean(accuracies)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1 Görevi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod Başarı Oranı: 82.17%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats\n",
    "\n",
    "# Veriyi Churn_Modelling.xlsx veriyi yükleme yapıcak\n",
    "df = pd.read_excel('Churn_Modelling.xlsx')\n",
    "\n",
    "# Kategorik özellikleri sayısallaştırma\n",
    "df = pd.get_dummies(df, columns=['Geography', 'Gender'], drop_first=True)\n",
    "\n",
    "# Boş değerleri en çok görülen değer ile doldurma işlemini yapar.\n",
    "np.random.seed(42)\n",
    "missing_indices = np.random.choice(df.index, size=(int(0.1 * len(df))), replace=False)\n",
    "df.loc[missing_indices, 'CreditScore'] = np.nan\n",
    "df.fillna(df.mode().iloc[0], inplace=True)\n",
    "\n",
    "# Sınıflandırma görevi ile alakasız kolonları silme\n",
    "df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)\n",
    "\n",
    "# Min-Max normalizasyonu\n",
    "df = (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "\n",
    "# Aşağıdaki kod satırında drop ile Bağımsız x değişkeninde Exited sütununu siler\n",
    "X = df.drop('Exited', axis=1)\n",
    "# Aşağıdaki kod satırında ise y değişkeninde drop olmadığı için y değişkeni exited sütununu içermiş olur.\n",
    "y = df['Exited']\n",
    "# Veriyi eğitim ve test setlerine ayırma oranına göre ayırma işlemi.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# K değerlerini içeren liste.\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "\n",
    "# Tahmin array listeleri.\n",
    "tahmin_1 = [] \n",
    "tahmin_3 = []\n",
    "tahmin_5 = []\n",
    "tahmin_7 = []\n",
    "tahmin_9 = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    # k=1\n",
    "    knn_classifier_1 = KNeighborsClassifier(n_neighbors=1)\n",
    "    knn_classifier_1.fit(X_train, y_train)\n",
    "    y_pred_1 = knn_classifier_1.predict(X_test.iloc[i:i+1])\n",
    "    tahmin_1.append(y_pred_1[0])\n",
    "\n",
    "    # k=3\n",
    "    knn_classifier_3 = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn_classifier_3.fit(X_train, y_train)\n",
    "    y_pred_3 = knn_classifier_3.predict(X_test.iloc[i:i+1])\n",
    "    tahmin_3.append(y_pred_3[0])\n",
    "\n",
    "    # k=5\n",
    "    knn_classifier_5 = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn_classifier_5.fit(X_train, y_train)\n",
    "    y_pred_5 = knn_classifier_5.predict(X_test.iloc[i:i+1])\n",
    "    tahmin_5.append(y_pred_5[0])\n",
    "\n",
    "    # k=7\n",
    "    knn_classifier_7 = KNeighborsClassifier(n_neighbors=7)\n",
    "    knn_classifier_7.fit(X_train, y_train)\n",
    "    y_pred_7 = knn_classifier_7.predict(X_test.iloc[i:i+1])\n",
    "    tahmin_7.append(y_pred_7[0])\n",
    "\n",
    "    # k=9\n",
    "    knn_classifier_9 = KNeighborsClassifier(n_neighbors=9)\n",
    "    knn_classifier_9.fit(X_train, y_train)\n",
    "    y_pred_9 = knn_classifier_9.predict(X_test.iloc[i:i+1])\n",
    "    tahmin_9.append(y_pred_9[0])\n",
    "\n",
    "# Tahmin array'lerini yatay olarak birleştirme işlemini gerçekleştiriyor yatay denildiği için vstack kullanıyoruz.\n",
    "tahmin_matrix = np.vstack([tahmin_1, tahmin_3, tahmin_5, tahmin_7, tahmin_9]).T\n",
    "\n",
    "# Her bir satırdaki en çok görülen değeri final tahmin olarak hesaplama\n",
    "final_predictions_mode = np.array(stats.mode([tahmin_1, tahmin_3, tahmin_5, tahmin_7, tahmin_9], axis=0)[0]).flatten()\n",
    "accuracy_mode = accuracy_score(y_test, final_predictions_mode)\n",
    "print(f\"Mod Başarı Oranı: {accuracy_mode * 100:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
